#!/usr/bin/env python3
"""
æ¼”ç¤ºè„šæœ¬ï¼šå±•ç¤º Mem0 é›†æˆçš„å®Œæ•´æµç¨‹

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†ï¼š
1. é’‰é’‰æ¶ˆæ¯æ¥æ”¶
2. Mem0 add() - å­˜å…¥å¯¹è¯
3. Mem0 search() - è·å–è®°å¿†
4. æ‹¼æ¥ Prompt
5. è°ƒç”¨ LLM
6. è¿”å›å›å¤

è¿è¡Œæ–¹å¼: python3 demo_mem0_flow.py
"""

import sys
import os
import json
from unittest.mock import Mock, patch, MagicMock

# Setup path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from dingbot.mem0_manager import Mem0Manager
from dingbot.agent import analyze_and_reply


def print_step(step_num, title, content=""):
    """Print a formatted step."""
    print(f"\n{'='*70}")
    print(f"æ­¥éª¤ {step_num}: {title}")
    print(f"{'='*70}")
    if content:
        print(content)


def demo_simple_conversation():
    """æ¼”ç¤ºç®€å•çš„å¯¹è¯æµç¨‹ã€‚"""
    print("\n" + "â–“" * 70)
    print("â–“  æ¼”ç¤ºï¼šåŸºäº Mem0 çš„ä¸ªæ€§åŒ–èŠå¤©")
    print("â–“" * 70)

    # Mock Mem0 Manager
    with patch('dingbot.agent.get_mem0_manager') as MockGetMem0, \
         patch('dingbot.agent._call_model') as MockCall, \
         patch('dingbot.agent.get_user_memories') as MockGetMemories:
        
        # Setup mock Mem0 manager
        mock_mem0_mgr = MagicMock()
        MockGetMem0.return_value = mock_mem0_mgr
        
        # Scenario: User is learning machine learning
        user_id = "user_alice_123"
        sender_name = "Alice"
        
        print_step(1, "é’‰é’‰æ¶ˆæ¯æ¥æ”¶", 
                  f"ç”¨æˆ· ID: {user_id}\n"
                  f"ç”¨æˆ·å: {sender_name}\n"
                  f"æ¶ˆæ¯: æœ€è¿‘åœ¨å­¦æ·±åº¦å­¦ä¹ ï¼Œæœ‰ç‚¹å›°éš¾")
        
        # Message to process
        user_message = "æœ€è¿‘åœ¨å­¦æ·±åº¦å­¦ä¹ ï¼Œæœ‰ç‚¹å›°éš¾"
        
        # Step 1: Mem0 add - Store the conversation
        print_step(2, "Mem0 add() - å­˜å…¥å½“å‰å¯¹è¯",
                  f"å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ° Mem0 é•¿æœŸè®°å¿†ä¸­...\n"
                  f"å†…å®¹: {user_message}\n"
                  f"ç”¨æˆ· ID: {user_id}")
        
        mock_mem0_mgr.add_memory.return_value = "mem_id_xyz789"
        
        # Step 2: Mem0 search - Get relevant memories
        print_step(3, "Mem0 search() - è·å–ç›¸å…³è®°å¿†",
                  "æ ¹æ®å½“å‰æ¶ˆæ¯æœç´¢ç›¸å…³çš„å†å²è®°å¿†...")
        
        memories_found = [
            {"memory": "Alice ä¹‹å‰æåˆ°å–œæ¬¢ç¼–ç¨‹å’Œæ•°æ®ç§‘å­¦", "score": 0.92},
            {"memory": "Alice ä½¿ç”¨ Python å’Œ PyTorch ç¼–ç¨‹", "score": 0.88},
            {"memory": "Alice æ˜¯ä¸€ååˆçº§æ•°æ®å·¥ç¨‹å¸ˆ", "score": 0.85}
        ]
        mock_mem0_mgr.search_memories.return_value = memories_found
        
        print(f"âœ“ æ‰¾åˆ° {len(memories_found)} æ¡ç›¸å…³è®°å¿†:")
        for i, mem in enumerate(memories_found, 1):
            print(f"  {i}. {mem['memory']} (ç›¸å…³åº¦: {mem['score']})")
        
        # Step 3: Format memories into context
        print_step(4, "æ ¼å¼åŒ–è®°å¿†ä¸ºä¸Šä¸‹æ–‡",
                  "å°†ç›¸å…³è®°å¿†è½¬æ¢ä¸ºæç¤ºè¯ä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯...")
        
        formatted_context = (
            "- Alice ä¹‹å‰æåˆ°å–œæ¬¢ç¼–ç¨‹å’Œæ•°æ®ç§‘å­¦\n"
            "- Alice ä½¿ç”¨ Python å’Œ PyTorch ç¼–ç¨‹\n"
            "- Alice æ˜¯ä¸€ååˆçº§æ•°æ®å·¥ç¨‹å¸ˆ"
        )
        mock_mem0_mgr.format_memories_as_context.return_value = formatted_context
        
        print("æ ¼å¼åŒ–åçš„ä¸Šä¸‹æ–‡:\n" + formatted_context)
        
        # Step 4: Build prompt
        print_step(5, "æ‹¼æ¥ Prompt",
                  "å°†è®°å¿†ã€ç”¨æˆ·æ¶ˆæ¯å’Œç³»ç»ŸæŒ‡ä»¤ç»„åˆæˆå®Œæ•´çš„æç¤ºè¯...")
        
        system_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªè´´å¿ƒä¸”è®°å¿†åŠ›è¶…ç¾¤çš„åŠ©æ‰‹ã€‚è¯·ç®€æ´ã€è‡ªç„¶åœ°å›å¤ç”¨æˆ· 'Alice'ã€‚"
            "\n\nå…³äºç”¨æˆ·çš„ç›¸å…³ä¿¡æ¯ï¼ˆåŸºäºå†å²å¯¹è¯ï¼‰ï¼š\n"
            f"{formatted_context}"
            f"\n\nç”¨æˆ·æ¶ˆæ¯:\n{user_message}"
            "\n\nè¯·è¿”å› JSON: {\"reply\": <å›å¤æ–‡æœ¬>}ï¼Œä¸è¦åŒ…å«å…¶å®ƒå†…å®¹ã€‚"
        )
        
        print("ç”Ÿæˆçš„å®Œæ•´ Prompt:\n" + system_prompt)
        
        # Step 5: Call LLM
        print_step(6, "è°ƒç”¨ LLM (Gemini)",
                  "ä½¿ç”¨ä¸Šä¸‹æ–‡è°ƒç”¨è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸ªæ€§åŒ–å›å¤...")
        
        llm_response = {
            "reply": "æˆ‘çœ‹ä½ åœ¨å­¦ä¹ æ·±åº¦å­¦ä¹ å‘¢ï¼è¿™ç¡®å®æ˜¯ä¸ªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯å¯¹åˆçº§çš„æ•°æ®å·¥ç¨‹å¸ˆæ¥è¯´ã€‚ä¸è¿‡æ ¹æ®æˆ‘çš„è®°å¿†ï¼Œä½ å·²ç»å¾ˆæ“…é•¿ Python å’Œ PyTorch äº†ï¼Œç›¸ä¿¡ä½ èƒ½æŒæ¡çš„ï¼å»ºè®®å¯ä»¥ä»ä¸€äº›ç»å…¸çš„æ·±åº¦å­¦ä¹ é¡¹ç›®å¼€å§‹ï¼Œæ¯”å¦‚ MNIST è¯†åˆ«æˆ–è€… CNN å›¾åƒåˆ†ç±»ã€‚åŠ æ²¹ï¼ğŸ’ª"
        }
        mock_mem0_mgr.format_memories_as_context.return_value = formatted_context
        MockGetMemories.return_value = []
        MockCall.return_value = json.dumps(llm_response)
        
        print(f"LLM å›å¤:\n{llm_response['reply']}")
        
        # Execute the complete flow
        print_step(7, "æ‰§è¡Œå®Œæ•´æµç¨‹",
                  "è°ƒç”¨ agent.analyze_and_reply() æ‰§è¡Œå®Œæ•´çš„æµç¨‹...")
        
        result = analyze_and_reply(user_message, sender_name, user_id)
        
        print(f"æœ€ç»ˆè¿”å›ç»“æœ:\n{json.dumps(result, ensure_ascii=False, indent=2)}")
        
        # Verify the flow
        print_step(8, "æµç¨‹éªŒè¯",
                  "éªŒè¯æ¯ä¸ªæ­¥éª¤æ˜¯å¦æ­£ç¡®æ‰§è¡Œ...")
        
        checks = [
            ("Mem0 add() å·²è°ƒç”¨", mock_mem0_mgr.add_memory.called),
            ("Mem0 search() å·²è°ƒç”¨", mock_mem0_mgr.search_memories.called),
            ("è®°å¿†æ ¼å¼åŒ–å·²æ‰§è¡Œ", mock_mem0_mgr.format_memories_as_context.called),
            ("LLM å·²è°ƒç”¨", MockCall.called),
            ("å›å¤å·²è¿”å›", bool(result.get("reply")))
        ]
        
        all_passed = True
        for check_name, check_result in checks:
            status = "âœ…" if check_result else "âŒ"
            print(f"{status} {check_name}")
            all_passed = all_passed and check_result
        
        print("\n" + "=" * 70)
        if all_passed:
            print("âœ… å®Œæ•´æµç¨‹æµ‹è¯• PASSED")
        else:
            print("âŒ å®Œæ•´æµç¨‹æµ‹è¯• FAILED")
        print("=" * 70)
        
        return all_passed


def demo_multi_turn_conversation():
    """æ¼”ç¤ºå¤šè½®å¯¹è¯çš„è®°å¿†ç´¯ç§¯ã€‚"""
    print("\n\n" + "â–“" * 70)
    print("â–“  æ¼”ç¤ºï¼šå¤šè½®å¯¹è¯ä¸­çš„è®°å¿†ç´¯ç§¯")
    print("â–“" * 70)
    
    with patch('dingbot.agent.get_mem0_manager') as MockGetMem0, \
         patch('dingbot.agent._call_model') as MockCall, \
         patch('dingbot.agent.get_user_memories') as MockGetMemories:
        
        mock_mem0_mgr = MagicMock()
        MockGetMem0.return_value = mock_mem0_mgr
        
        user_id = "user_bob_456"
        sender_name = "Bob"
        
        # Simulate multi-turn conversation
        conversations = [
            ("ä½ å¥½ï¼Œæˆ‘å« Bob", "å¾ˆé«˜å…´è®¤è¯†ä½ ï¼"),
            ("æˆ‘å–œæ¬¢æ—…æ¸¸", "æ—…æ¸¸å¾ˆæœ‰è¶£ï¼Œä½ æœ€å–œæ¬¢å»å“ªå„¿ï¼Ÿ"),
            ("æœ€è¿‘å»è¿‡æ—¥æœ¬", "æ—¥æœ¬å¾ˆç¾ï¼ä½ åœ¨æ—¥æœ¬çš„å“ªäº›åœ°æ–¹ç©è¿‡ï¼Ÿ"),
            ("å»è¿‡ä¸œäº¬å’Œäº¬éƒ½", "ä¸œäº¬å’Œäº¬éƒ½éƒ½æ˜¯å¾ˆæ£’çš„åœ°æ–¹ï¼Œåˆ†åˆ«æœ‰ç°ä»£å’Œä¼ ç»Ÿçš„ç‰¹è‰²ã€‚")
        ]
        
        for turn, (user_msg, ai_reply) in enumerate(conversations, 1):
            print(f"\n--- å¯¹è¯è½®æ¬¡ {turn} ---")
            print(f"ç”¨æˆ·: {user_msg}")
            
            # Mock the memories accumulation
            memories_count = turn  # Simulating memory grows with each turn
            mock_mem0_mgr.add_memory.return_value = f"mem_id_{turn}"
            mock_mem0_mgr.search_memories.return_value = [
                {"memory": f"Bob åœ¨å¯¹è¯è½®æ¬¡ {i} æåˆ°çš„ä¿¡æ¯", "score": 0.9 - i*0.05}
                for i in range(1, min(turn + 1, 4))
            ]
            mock_mem0_mgr.format_memories_as_context.return_value = (
                "\n".join([f"- Bob åœ¨å¯¹è¯è½®æ¬¡ {i} æåˆ°çš„ä¿¡æ¯" 
                          for i in range(1, min(turn + 1, 4))])
            )
            MockGetMemories.return_value = []
            MockCall.return_value = json.dumps({"reply": ai_reply})
            
            result = analyze_and_reply(user_msg, sender_name, user_id)
            print(f"AI: {result.get('reply', 'æ— å›å¤')}")
            print(f"âœ“ å·²æ·»åŠ è®°å¿†ï¼Œå½“å‰è®°å¿†ç´¯ç§¯ {memories_count} æ¡")
        
        print("\n" + "=" * 70)
        print("âœ… å¤šè½®å¯¹è¯æ¼”ç¤ºå®Œæˆ")
        print("=" * 70)


if __name__ == "__main__":
    try:
        # Run demos
        passed = demo_simple_conversation()
        demo_multi_turn_conversation()
        
        print("\n\n" + "â–“" * 70)
        print("â–“  æ¼”ç¤ºæ€»ç»“")
        print("â–“" * 70)
        print("""
å®Œæ•´çš„ Mem0 é›†æˆæµç¨‹å±•ç¤ºå¦‚ä¸‹:

1. âœ… é’‰é’‰æ¥æ”¶æ¶ˆæ¯
   â””â”€ æœåŠ¡å™¨ webhook æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯

2. âœ… Mem0 add() - å­˜å…¥å½“å‰å¯¹è¯
   â””â”€ å°†æ¶ˆæ¯å­˜å…¥ Mem0 çš„é•¿æœŸè®°å¿†æ•°æ®åº“

3. âœ… Mem0 search() - è·å–ç›¸å…³è®°å¿†
   â””â”€ æ ¹æ®å½“å‰æ¶ˆæ¯è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œè·å–ç›¸å…³çš„å†å²è®°å¿†

4. âœ… æ‹¼æ¥ Prompt - æ³¨å…¥è®°å¿†ä¸Šä¸‹æ–‡
   â””â”€ å°†ç›¸å…³è®°å¿†æ ¼å¼åŒ–å¹¶æ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºè¯

5. âœ… è°ƒç”¨ LLM - ç”Ÿæˆä¸ªæ€§åŒ–å›å¤
   â””â”€ ä½¿ç”¨ Gemini æ¨¡å‹åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå›å¤

6. âœ… è¿”å›ç»™é’‰é’‰
   â””â”€ å°† AI å›å¤å‘é€å›é’‰é’‰ä¼šè¯

å…³é”®ç‰¹æ€§:
â€¢ åŸºäºå‘é‡ç›¸ä¼¼åº¦æœç´¢ç›¸å…³è®°å¿†
â€¢ è‡ªåŠ¨ç´¯ç§¯ç”¨æˆ·è®°å¿†ç”¨äºé•¿æœŸä¸ªæ€§åŒ–
â€¢ æ”¯æŒå¤šç”¨æˆ·å¹¶å‘å¯¹è¯
â€¢ å¯é…ç½®çš„è®°å¿†æœç´¢æ•°é‡å’Œç›¸å…³æ€§
â€¢ æ”¯æŒæœ¬åœ°å’Œäº‘ç«¯å­˜å‚¨

å¦‚éœ€éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ:
1. é…ç½® OpenAI API Key (Mem0 æ‰€éœ€)
2. é…ç½® Gemini API Key (LLM æ‰€éœ€)
3. é…ç½®é’‰é’‰ ACCESS_TOKEN å’Œ SECRET
4. ä½¿ç”¨ docker-compose up å¯åŠ¨æœåŠ¡
        """)
        print("â–“" * 70)
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
